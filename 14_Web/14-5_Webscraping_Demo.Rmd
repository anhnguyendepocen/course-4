---
title: "Lecture Code"
author: "Pete Cuppernull"
date: "8/13/2019"
output:
  html_document: default
  pdf_document: default
---

## Scraping Presidential Statements

To demonstrate webscraping in R, we're going to collect records on presidential statements here: https://www.presidency.ucsb.edu/

Let's say we're interested in how presidents speak about "space exploration". On the website, we punch in this search term, and we get the [following 295 results](https://www.presidency.ucsb.edu/advanced-search?field-keywords=%22space+exploration%22&field-keywords2=&field-keywords3=&from%5Bdate%5D=&to%5Bdate%5D=&person2=&items_per_page=100). 

Our goal is to scrape these records, and store pertenant information in a dataframe.

Load the following packages to get started:

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(rvest)
library(stringr)
library(purrr)
library(knitr)
```

### Using `RVest` to Read HTML

The package `RVest` allows us to:

1. Collect the HTML source code of a webpage
2. Read the HTML of the page
3. Select and keep certain elements of the page that are of interest

Let's start with step one. We use the `read_html` function to call the results URL and grab the HTML response. Store this result as an object.

```{r}
space <- read_html("https://www.presidency.ucsb.edu/advanced-search?field-keywords=%22space+exploration%22&field-keywords2=&field-keywords3=&from%5Bdate%5D=&to%5Bdate%5D=&person2=&items_per_page=100")

#Let's take a look at the object we just created
space
```
This is pretty messy. We need to use `RVest` to make this information more useable.

### Find Page Elements

`RVest` has a number of functions to find information on a page. Like other webscraping tools, RVest lets you find elements by their:

1. HTML tags
2. HTML Attributes
3. CSS Selectors

Let's search first for HTML tags.

The function `html_nodes` searches a parsed HTML object to find all the elements with a particular HTML tag, and returns all of those elements.

What does the example below do?

```{r}
html_nodes(space, "a")
```

That's a lot of results! Many elements on a page will have the same HTML tag. For instance, if you search for everything with the `a` tag, you're likely to get a lot of stuff, much of which you don't want. 

In our case, we only want the links of Document Titles:

```{r}
knitr::include_graphics(path = "img/scraping_links.png")
```

What if we wanted to search for HTML tags **only** with certain attributes, like particular CSS classes?

We can do this by modifying our argument in `html_nodes` to look for a more specific CSS tag.

#### Selector Gadget {-}

In order to easily identify these more specific tags, we can use __Selector Gadget__.

Install Selector Gadget in your browser. Once installed, run Selector Gadget and simply click on the type of information you want to select from the webpage. Once this is selected, you can then click the pieces of information you **don't** want to keep. Do this until only the pieces you want to keep remain highlighted, then copy the selector from the bottom pane.

You can use this new tag in `html_nodes`.

### Get Attributes and Text of Elements

Once we identify elements, we want to access information in that element. Oftentimes this means two things:

1) Text
2) Attributes

Getting the text inside an element is pretty straightforward. We can use the `html_text()` command  inside of `RVest` to get the text of an element:

```{r}
#Scrape individual document page
document1 <- read_html("https://www.presidency.ucsb.edu/documents/special-message-the-congress-relative-space-science-and-exploration")

#identify element with Speaker name
speaker <- html_nodes(document1, ".diet-title a") %>% 
  html_text() #select text of element

speaker
```

You can access a tag's attributes using `html_attr`. For example, we often want to get a URL from an `a` (link) element. This is the URL is the link "points" to. It's contained in the attribut `href`:

```{r}
speaker_link <- html_nodes(document1, ".diet-title a") %>% 
  html_attr("href")
speaker_link
```

### Let's DO this.

Believe it or not, that's all you need to scrape a website. Let's apply these skills to scrape a sample document from the UCSB website -- the [first item in our search results]("http://www.presidency.ucsb.edu/documents/letter-t-keith-glennan-administrator-national-aeronautics-and-space-administration"). 

We'll collect the document's date, speaker, title, and full text.

1. Date

```{r, message=FALSE}
document1 <- read_html("https://www.presidency.ucsb.edu/documents/special-message-the-congress-relative-space-science-and-exploration")

date <- html_nodes(document1, ".date-display-single") %>%
  html_text() %>% # grab element text
  mdy() #format using lubridate
date
```

2. Speaker

```{r, message=FALSE}
#Speaker
speaker <- html_nodes(document1, ".diet-title a") %>%
  html_text()
speaker
```

3. Title

```{r, message=FALSE}
#Title
title <- html_nodes(document1, "h1") %>%
  html_text()
title
```

4. Text

```{r, message=FALSE}
#Text
text <- html_nodes(document1, "div.field-docs-content") %>%
          html_text()

#this is a long document, so let's just display the first 1000 characters
text %>% substr(1, 1000) 
```

### Challenge 1: Make a function

Make a function called `scrape_docs` that accepts a URL of an individual document, scrapes the page,  and returns a list containing the document's date, speaker, title, and full text.

This involves:

- Requesting the HTML of the webpage using the full URL and RVest.
- Using RVest to locate all elements on the page we want to save.
- Saving each of these items into a list.

```{r}
scrape_doc <- function(URL){
  doc <- read_html(URL)
  
  speaker <- html_nodes(doc, ".diet-title a") %>% 
                                        html_text()
  
  date <- html_nodes(doc, ".date-display-single") %>%
                                        html_text() %>%
                                        mdy()
  
  title <- html_nodes(doc, "h1") %>%
                                        html_text()
  
  text <- html_nodes(doc, "div.field-docs-content") %>%
                                        html_text()
  
  return(list(speaker = speaker, date = date, title = title, text = text))
  
}

# uncomment to test
# scrape_doc("https://www.presidency.ucsb.edu/documents/letter-t-keith-glennan-administrator-national-aeronautics-and-space-administration")
```
